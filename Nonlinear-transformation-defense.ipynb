{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce digits of power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "(X, y), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10,12,14,16,18,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255\n",
    "XT=x_test/255\n",
    "yT=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(60000, 28**2)\n",
    "XT=XT.reshape(10000, 28**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call MNIST and keep 3s and 7s\n",
    "#mnist = sklearn.datasets.fetch_mldata(\"MNIST original\")\n",
    "\n",
    "# Rescale the data and extract all images for two digits\n",
    "#X, y = mnist.data / 255., mnist.target\n",
    "\n",
    "index = np.where((y == 3) | (y == 7))[0]\n",
    "X0,y = X[index], y[index]\n",
    "\n",
    "Index = np.where((yT == 3) | (yT == 7))[0]\n",
    "XT,yT = XT[Index], yT[Index]\n",
    "\n",
    "X0_train1, X0_train2, y_train1, y_train2 = sklearn.model_selection.train_test_split(X0, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68541312\n",
      "Iteration 2, loss = 0.53577560\n",
      "Iteration 3, loss = 0.44939525\n",
      "Iteration 4, loss = 0.40569086\n",
      "Iteration 5, loss = 0.37748546\n",
      "Iteration 6, loss = 0.35651733\n",
      "Iteration 7, loss = 0.33959157\n",
      "Iteration 8, loss = 0.32514813\n",
      "Iteration 9, loss = 0.31250971\n",
      "Iteration 10, loss = 0.30115191\n",
      "Iteration 11, loss = 0.29086323\n",
      "Iteration 12, loss = 0.28141328\n",
      "Iteration 13, loss = 0.27268393\n",
      "Iteration 14, loss = 0.26459546\n",
      "Iteration 15, loss = 0.25704780\n",
      "Iteration 16, loss = 0.24999617\n",
      "Iteration 17, loss = 0.24336052\n",
      "Iteration 18, loss = 0.23714605\n",
      "Iteration 19, loss = 0.23126334\n",
      "Iteration 20, loss = 0.22575366\n",
      "Iteration 21, loss = 0.22048387\n",
      "Iteration 22, loss = 0.21550662\n",
      "Iteration 23, loss = 0.21078659\n",
      "Iteration 24, loss = 0.20632043\n",
      "Iteration 25, loss = 0.20200823\n",
      "Iteration 26, loss = 0.19795028\n",
      "Iteration 27, loss = 0.19404559\n",
      "Iteration 28, loss = 0.19034589\n",
      "Iteration 29, loss = 0.18679659\n",
      "Iteration 30, loss = 0.18336530\n",
      "Iteration 31, loss = 0.18013583\n",
      "Iteration 32, loss = 0.17698822\n",
      "Iteration 33, loss = 0.17399304\n",
      "Iteration 34, loss = 0.17112026\n",
      "Iteration 35, loss = 0.16833399\n",
      "Iteration 36, loss = 0.16566085\n",
      "Iteration 37, loss = 0.16311603\n",
      "Iteration 38, loss = 0.16062784\n",
      "Iteration 39, loss = 0.15826222\n",
      "Iteration 40, loss = 0.15596408\n",
      "Iteration 41, loss = 0.15374874\n",
      "Iteration 42, loss = 0.15163449\n",
      "Iteration 43, loss = 0.14954881\n",
      "Iteration 44, loss = 0.14754630\n",
      "Iteration 45, loss = 0.14566211\n",
      "Iteration 46, loss = 0.14376274\n",
      "Iteration 47, loss = 0.14194406\n",
      "Iteration 48, loss = 0.14019017\n",
      "Iteration 49, loss = 0.13850310\n",
      "Iteration 50, loss = 0.13684741\n",
      "Iteration 51, loss = 0.13527605\n",
      "Iteration 52, loss = 0.13372484\n",
      "Iteration 53, loss = 0.13221051\n",
      "Iteration 54, loss = 0.13075637\n",
      "Iteration 55, loss = 0.12932604\n",
      "Iteration 56, loss = 0.12795852\n",
      "Iteration 57, loss = 0.12660966\n",
      "Iteration 58, loss = 0.12530263\n",
      "Iteration 59, loss = 0.12402780\n",
      "Iteration 60, loss = 0.12280105\n",
      "Iteration 61, loss = 0.12159050\n",
      "Iteration 62, loss = 0.12041986\n",
      "Iteration 63, loss = 0.11929809\n",
      "Iteration 64, loss = 0.11814572\n",
      "Iteration 65, loss = 0.11706815\n",
      "Iteration 66, loss = 0.11600588\n",
      "Iteration 67, loss = 0.11497474\n",
      "Iteration 68, loss = 0.11393044\n",
      "Iteration 69, loss = 0.11294447\n",
      "Iteration 70, loss = 0.11198395\n",
      "Iteration 71, loss = 0.11102984\n",
      "Iteration 72, loss = 0.11010004\n",
      "Iteration 73, loss = 0.10919439\n",
      "Iteration 74, loss = 0.10831654\n",
      "Iteration 75, loss = 0.10745918\n",
      "Iteration 76, loss = 0.10660532\n",
      "Iteration 77, loss = 0.10576859\n",
      "Iteration 78, loss = 0.10495699\n",
      "Iteration 79, loss = 0.10414591\n",
      "Iteration 80, loss = 0.10338527\n",
      "Iteration 81, loss = 0.10260234\n",
      "Iteration 82, loss = 0.10185131\n",
      "Iteration 83, loss = 0.10111118\n",
      "Iteration 84, loss = 0.10040082\n",
      "Iteration 85, loss = 0.09967392\n",
      "Iteration 86, loss = 0.09898088\n",
      "Iteration 87, loss = 0.09829853\n",
      "Iteration 88, loss = 0.09761975\n",
      "Iteration 89, loss = 0.09695875\n",
      "Iteration 90, loss = 0.09631018\n",
      "Iteration 91, loss = 0.09568184\n",
      "Iteration 92, loss = 0.09504286\n",
      "Iteration 93, loss = 0.09443002\n",
      "Iteration 94, loss = 0.09382915\n",
      "Iteration 95, loss = 0.09324595\n",
      "Iteration 96, loss = 0.09265511\n",
      "Iteration 97, loss = 0.09208176\n",
      "Iteration 98, loss = 0.09153330\n",
      "Iteration 99, loss = 0.09095100\n",
      "Iteration 100, loss = 0.09041244\n",
      "Iteration 101, loss = 0.08988603\n",
      "Iteration 102, loss = 0.08934353\n",
      "Iteration 103, loss = 0.08883344\n",
      "Iteration 104, loss = 0.08827373\n",
      "Iteration 105, loss = 0.08776769\n",
      "Iteration 106, loss = 0.08727645\n",
      "Iteration 107, loss = 0.08677965\n",
      "Iteration 108, loss = 0.08628032\n",
      "Iteration 109, loss = 0.08581180\n",
      "Iteration 110, loss = 0.08535138\n",
      "Iteration 111, loss = 0.08487500\n",
      "Iteration 112, loss = 0.08444770\n",
      "Iteration 113, loss = 0.08396197\n",
      "Iteration 114, loss = 0.08351430\n",
      "Iteration 115, loss = 0.08307968\n",
      "Iteration 116, loss = 0.08264859\n",
      "Iteration 117, loss = 0.08221378\n",
      "Iteration 118, loss = 0.08177893\n",
      "Iteration 119, loss = 0.08136116\n",
      "Iteration 120, loss = 0.08095686\n",
      "Iteration 121, loss = 0.08053508\n",
      "Iteration 122, loss = 0.08013422\n",
      "Iteration 123, loss = 0.07972253\n",
      "Iteration 124, loss = 0.07935577\n",
      "Iteration 125, loss = 0.07892267\n",
      "Iteration 126, loss = 0.07854620\n",
      "Iteration 127, loss = 0.07816659\n",
      "Iteration 128, loss = 0.07780547\n",
      "Iteration 129, loss = 0.07743287\n",
      "Iteration 130, loss = 0.07704572\n",
      "Iteration 131, loss = 0.07669016\n",
      "Iteration 132, loss = 0.07631671\n",
      "Iteration 133, loss = 0.07597390\n",
      "Iteration 134, loss = 0.07562398\n",
      "Iteration 135, loss = 0.07526289\n",
      "Iteration 136, loss = 0.07493375\n",
      "Iteration 137, loss = 0.07459392\n",
      "Iteration 138, loss = 0.07426363\n",
      "Iteration 139, loss = 0.07392224\n",
      "Iteration 140, loss = 0.07359743\n",
      "Iteration 141, loss = 0.07325425\n",
      "Iteration 142, loss = 0.07296168\n",
      "Iteration 143, loss = 0.07262532\n",
      "Iteration 144, loss = 0.07230659\n",
      "Iteration 145, loss = 0.07200792\n",
      "Iteration 146, loss = 0.07170782\n",
      "Iteration 147, loss = 0.07142906\n",
      "Iteration 148, loss = 0.07109504\n",
      "Iteration 149, loss = 0.07079011\n",
      "Iteration 150, loss = 0.07050400\n",
      "Iteration 151, loss = 0.07018596\n",
      "Iteration 152, loss = 0.06989291\n",
      "Iteration 153, loss = 0.06959572\n",
      "Iteration 154, loss = 0.06933262\n",
      "Iteration 155, loss = 0.06904153\n",
      "Iteration 156, loss = 0.06874363\n",
      "Iteration 157, loss = 0.06850753\n",
      "Iteration 158, loss = 0.06820006\n",
      "Iteration 159, loss = 0.06791280\n",
      "Iteration 160, loss = 0.06765252\n",
      "Iteration 161, loss = 0.06741360\n",
      "Iteration 162, loss = 0.06709992\n",
      "Iteration 163, loss = 0.06685355\n",
      "Iteration 164, loss = 0.06655885\n",
      "Iteration 165, loss = 0.06630518\n",
      "Iteration 166, loss = 0.06604788\n",
      "Iteration 167, loss = 0.06578577\n",
      "Iteration 168, loss = 0.06552614\n",
      "Iteration 169, loss = 0.06527357\n",
      "Iteration 170, loss = 0.06507220\n",
      "Iteration 171, loss = 0.06476626\n",
      "Iteration 172, loss = 0.06453160\n",
      "Iteration 173, loss = 0.06429473\n",
      "Iteration 174, loss = 0.06404121\n",
      "Iteration 175, loss = 0.06379688\n",
      "Iteration 176, loss = 0.06356061\n",
      "Iteration 177, loss = 0.06331171\n",
      "Iteration 178, loss = 0.06308384\n",
      "Iteration 179, loss = 0.06284097\n",
      "Iteration 180, loss = 0.06262508\n",
      "Iteration 181, loss = 0.06238103\n",
      "Iteration 182, loss = 0.06215030\n",
      "Iteration 183, loss = 0.06193011\n",
      "Iteration 184, loss = 0.06170510\n",
      "Iteration 185, loss = 0.06146766\n",
      "Iteration 186, loss = 0.06126543\n",
      "Iteration 187, loss = 0.06103245\n",
      "Iteration 188, loss = 0.06082013\n",
      "Iteration 189, loss = 0.06059544\n",
      "Iteration 190, loss = 0.06037048\n",
      "Iteration 191, loss = 0.06016704\n",
      "Iteration 192, loss = 0.05995469\n",
      "Iteration 193, loss = 0.05974090\n",
      "Iteration 194, loss = 0.05956197\n",
      "Iteration 195, loss = 0.05932236\n",
      "Iteration 196, loss = 0.05916238\n",
      "Iteration 197, loss = 0.05893199\n",
      "Iteration 198, loss = 0.05872432\n",
      "Iteration 199, loss = 0.05852875\n",
      "Iteration 200, loss = 0.05832121\n",
      "Iteration 201, loss = 0.05813848\n",
      "Iteration 202, loss = 0.05792831\n",
      "Iteration 203, loss = 0.05773445\n",
      "Iteration 204, loss = 0.05754993\n",
      "Iteration 205, loss = 0.05735040\n",
      "Iteration 206, loss = 0.05716573\n",
      "Iteration 207, loss = 0.05697741\n",
      "Iteration 208, loss = 0.05678940\n",
      "Iteration 209, loss = 0.05660882\n",
      "Iteration 210, loss = 0.05641793\n",
      "Iteration 211, loss = 0.05622658\n",
      "Iteration 212, loss = 0.05608225\n",
      "Iteration 213, loss = 0.05587332\n",
      "Iteration 214, loss = 0.05567908\n",
      "Iteration 215, loss = 0.05550027\n",
      "Iteration 216, loss = 0.05532259\n",
      "Iteration 217, loss = 0.05514778\n",
      "Iteration 218, loss = 0.05497670\n",
      "Iteration 219, loss = 0.05482214\n",
      "Iteration 220, loss = 0.05463195\n",
      "Iteration 221, loss = 0.05444516\n",
      "Iteration 222, loss = 0.05429404\n",
      "Iteration 223, loss = 0.05410550\n",
      "Iteration 224, loss = 0.05395393\n",
      "Iteration 225, loss = 0.05375660\n",
      "Iteration 226, loss = 0.05359217\n",
      "Iteration 227, loss = 0.05344253\n",
      "Iteration 228, loss = 0.05328823\n",
      "Iteration 229, loss = 0.05312795\n",
      "Iteration 230, loss = 0.05296101\n",
      "Iteration 231, loss = 0.05279314\n",
      "Iteration 232, loss = 0.05263286\n",
      "Iteration 233, loss = 0.05249756\n",
      "Iteration 234, loss = 0.05230510\n",
      "Iteration 235, loss = 0.05214470\n",
      "Iteration 236, loss = 0.05200554\n",
      "Iteration 237, loss = 0.05184465\n",
      "Iteration 238, loss = 0.05168028\n",
      "Iteration 239, loss = 0.05152667\n",
      "Iteration 240, loss = 0.05137740\n",
      "Iteration 241, loss = 0.05120637\n",
      "Iteration 242, loss = 0.05106832\n",
      "Iteration 243, loss = 0.05093367\n",
      "Iteration 244, loss = 0.05076973\n",
      "Iteration 245, loss = 0.05060087\n",
      "Iteration 246, loss = 0.05044975\n",
      "Iteration 247, loss = 0.05031009\n",
      "Iteration 248, loss = 0.05015955\n",
      "Iteration 249, loss = 0.05002651\n",
      "Iteration 250, loss = 0.04988172\n",
      "Iteration 251, loss = 0.04971825\n",
      "Iteration 252, loss = 0.04956934\n",
      "Iteration 253, loss = 0.04941076\n",
      "Iteration 254, loss = 0.04927550\n",
      "Iteration 255, loss = 0.04912959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 256, loss = 0.04899027\n",
      "Iteration 257, loss = 0.04885523\n",
      "Iteration 258, loss = 0.04870860\n",
      "Iteration 259, loss = 0.04857240\n",
      "Iteration 260, loss = 0.04844051\n",
      "Iteration 261, loss = 0.04829386\n",
      "Iteration 262, loss = 0.04816432\n",
      "Iteration 263, loss = 0.04801669\n",
      "Iteration 264, loss = 0.04787733\n",
      "Iteration 265, loss = 0.04775583\n",
      "Iteration 266, loss = 0.04765826\n",
      "Iteration 267, loss = 0.04748637\n",
      "Iteration 268, loss = 0.04734198\n",
      "Iteration 269, loss = 0.04719824\n",
      "Iteration 270, loss = 0.04708690\n",
      "Iteration 271, loss = 0.04694742\n",
      "Iteration 272, loss = 0.04682536\n",
      "Iteration 273, loss = 0.04673551\n",
      "Iteration 274, loss = 0.04656541\n",
      "Iteration 275, loss = 0.04644075\n",
      "Iteration 276, loss = 0.04630798\n",
      "Iteration 277, loss = 0.04617923\n",
      "Iteration 278, loss = 0.04604478\n",
      "Iteration 279, loss = 0.04592386\n",
      "Iteration 280, loss = 0.04579218\n",
      "Iteration 281, loss = 0.04567971\n",
      "Iteration 282, loss = 0.04555257\n",
      "Iteration 283, loss = 0.04543510\n",
      "Iteration 284, loss = 0.04529762\n",
      "Iteration 285, loss = 0.04520423\n",
      "Iteration 286, loss = 0.04504494\n",
      "Iteration 287, loss = 0.04493486\n",
      "Iteration 288, loss = 0.04484908\n",
      "Iteration 289, loss = 0.04469119\n",
      "Iteration 290, loss = 0.04459046\n",
      "Iteration 291, loss = 0.04446704\n",
      "Iteration 292, loss = 0.04434708\n",
      "Iteration 293, loss = 0.04421124\n",
      "Iteration 294, loss = 0.04409776\n",
      "Iteration 295, loss = 0.04398367\n",
      "Iteration 296, loss = 0.04386091\n",
      "Iteration 297, loss = 0.04375854\n",
      "Iteration 298, loss = 0.04364347\n",
      "Iteration 299, loss = 0.04352801\n",
      "Iteration 300, loss = 0.04341095\n",
      "Iteration 301, loss = 0.04329045\n",
      "Iteration 302, loss = 0.04318247\n",
      "Iteration 303, loss = 0.04307625\n",
      "Iteration 304, loss = 0.04296413\n",
      "Iteration 305, loss = 0.04284700\n",
      "Iteration 306, loss = 0.04275212\n",
      "Iteration 307, loss = 0.04264231\n",
      "Iteration 308, loss = 0.04252761\n",
      "Iteration 309, loss = 0.04241456\n",
      "Iteration 310, loss = 0.04231380\n",
      "Iteration 311, loss = 0.04219639\n",
      "Iteration 312, loss = 0.04208692\n",
      "Iteration 313, loss = 0.04200903\n",
      "Iteration 314, loss = 0.04188010\n",
      "Iteration 315, loss = 0.04176866\n",
      "Iteration 316, loss = 0.04167564\n",
      "Iteration 317, loss = 0.04158387\n",
      "Iteration 318, loss = 0.04144710\n",
      "Iteration 319, loss = 0.04135025\n",
      "Iteration 320, loss = 0.04126108\n",
      "Iteration 321, loss = 0.04114776\n",
      "Iteration 322, loss = 0.04105135\n",
      "Iteration 323, loss = 0.04093853\n",
      "Iteration 324, loss = 0.04084254\n",
      "Iteration 325, loss = 0.04074821\n",
      "Iteration 326, loss = 0.04063366\n",
      "Iteration 327, loss = 0.04053174\n",
      "Iteration 328, loss = 0.04044076\n",
      "Iteration 329, loss = 0.04032916\n",
      "Iteration 330, loss = 0.04023122\n",
      "Iteration 331, loss = 0.04013914\n",
      "Iteration 332, loss = 0.04004182\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 333, loss = 0.03993693\n",
      "Iteration 334, loss = 0.03990846\n",
      "Iteration 335, loss = 0.03988867\n",
      "Iteration 336, loss = 0.03986961\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 337, loss = 0.03984786\n",
      "Iteration 338, loss = 0.03984259\n",
      "Iteration 339, loss = 0.03983924\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 340, loss = 0.03983479\n",
      "Iteration 341, loss = 0.03983393\n",
      "Iteration 342, loss = 0.03983310\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 343, loss = 0.03983222\n",
      "Iteration 344, loss = 0.03983202\n",
      "Iteration 345, loss = 0.03983185\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 346, loss = 0.03983171\n",
      "Iteration 347, loss = 0.03983164\n",
      "Iteration 348, loss = 0.03983164\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(4,), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=5, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_neural = sklearn.neural_network.MLPClassifier(activation = \"relu\", hidden_layer_sizes=(4,), max_iter = 500, solver='sgd', random_state=5, learning_rate = 'adaptive',verbose = 1)\n",
    "small_neural.fit(X0_train1,y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill(x,n,theta):\n",
    "#     return x**n\n",
    "    return x**n/(x**n + theta**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.5\n",
    "middle = np.zeros((len(Ns),len(X0_train2)))\n",
    "for idx_N,N in enumerate(Ns):\n",
    "    X = hill(X0_train2,N,theta)\n",
    "    middle[idx_N]=small_neural.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle=np.transpose(middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "master training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.73619562\n",
      "Iteration 2, loss = 0.69065154\n",
      "Iteration 3, loss = 0.67967535\n",
      "Iteration 4, loss = 0.66663165\n",
      "Iteration 5, loss = 0.64696989\n",
      "Iteration 6, loss = 0.63891733\n",
      "Iteration 7, loss = 0.63582994\n",
      "Iteration 8, loss = 0.63330591\n",
      "Iteration 9, loss = 0.63090694\n",
      "Iteration 10, loss = 0.62857559\n",
      "Iteration 11, loss = 0.62631527\n",
      "Iteration 12, loss = 0.62407103\n",
      "Iteration 13, loss = 0.62187739\n",
      "Iteration 14, loss = 0.61966153\n",
      "Iteration 15, loss = 0.61745975\n",
      "Iteration 16, loss = 0.61527359\n",
      "Iteration 17, loss = 0.61309793\n",
      "Iteration 18, loss = 0.61090161\n",
      "Iteration 19, loss = 0.60874349\n",
      "Iteration 20, loss = 0.60652451\n",
      "Iteration 21, loss = 0.60432527\n",
      "Iteration 22, loss = 0.60212148\n",
      "Iteration 23, loss = 0.59990186\n",
      "Iteration 24, loss = 0.59769070\n",
      "Iteration 25, loss = 0.59545594\n",
      "Iteration 26, loss = 0.59324350\n",
      "Iteration 27, loss = 0.59095376\n",
      "Iteration 28, loss = 0.58870101\n",
      "Iteration 29, loss = 0.58640909\n",
      "Iteration 30, loss = 0.58411125\n",
      "Iteration 31, loss = 0.58182271\n",
      "Iteration 32, loss = 0.57950738\n",
      "Iteration 33, loss = 0.57715322\n",
      "Iteration 34, loss = 0.57481867\n",
      "Iteration 35, loss = 0.57245675\n",
      "Iteration 36, loss = 0.57008791\n",
      "Iteration 37, loss = 0.56768564\n",
      "Iteration 38, loss = 0.56530602\n",
      "Iteration 39, loss = 0.56286608\n",
      "Iteration 40, loss = 0.56044441\n",
      "Iteration 41, loss = 0.55798625\n",
      "Iteration 42, loss = 0.55551557\n",
      "Iteration 43, loss = 0.55303120\n",
      "Iteration 44, loss = 0.55053975\n",
      "Iteration 45, loss = 0.54803849\n",
      "Iteration 46, loss = 0.54549890\n",
      "Iteration 47, loss = 0.54294766\n",
      "Iteration 48, loss = 0.54039340\n",
      "Iteration 49, loss = 0.53781494\n",
      "Iteration 50, loss = 0.53524002\n",
      "Iteration 51, loss = 0.53262774\n",
      "Iteration 52, loss = 0.52998812\n",
      "Iteration 53, loss = 0.52739513\n",
      "Iteration 54, loss = 0.52469101\n",
      "Iteration 55, loss = 0.52199685\n",
      "Iteration 56, loss = 0.51931912\n",
      "Iteration 57, loss = 0.51660359\n",
      "Iteration 58, loss = 0.51386071\n",
      "Iteration 59, loss = 0.51113736\n",
      "Iteration 60, loss = 0.50839715\n",
      "Iteration 61, loss = 0.50557836\n",
      "Iteration 62, loss = 0.50281219\n",
      "Iteration 63, loss = 0.50001611\n",
      "Iteration 64, loss = 0.49718057\n",
      "Iteration 65, loss = 0.49433483\n",
      "Iteration 66, loss = 0.49148732\n",
      "Iteration 67, loss = 0.48864058\n",
      "Iteration 68, loss = 0.48573530\n",
      "Iteration 69, loss = 0.48284131\n",
      "Iteration 70, loss = 0.47991238\n",
      "Iteration 71, loss = 0.47699523\n",
      "Iteration 72, loss = 0.47406408\n",
      "Iteration 73, loss = 0.47109986\n",
      "Iteration 74, loss = 0.46817303\n",
      "Iteration 75, loss = 0.46519393\n",
      "Iteration 76, loss = 0.46224580\n",
      "Iteration 77, loss = 0.45918797\n",
      "Iteration 78, loss = 0.45616596\n",
      "Iteration 79, loss = 0.45314618\n",
      "Iteration 80, loss = 0.45017025\n",
      "Iteration 81, loss = 0.44712236\n",
      "Iteration 82, loss = 0.44403027\n",
      "Iteration 83, loss = 0.44096631\n",
      "Iteration 84, loss = 0.43793083\n",
      "Iteration 85, loss = 0.43482568\n",
      "Iteration 86, loss = 0.43175814\n",
      "Iteration 87, loss = 0.42866895\n",
      "Iteration 88, loss = 0.42565920\n",
      "Iteration 89, loss = 0.42247452\n",
      "Iteration 90, loss = 0.41936173\n",
      "Iteration 91, loss = 0.41625220\n",
      "Iteration 92, loss = 0.41312793\n",
      "Iteration 93, loss = 0.41002624\n",
      "Iteration 94, loss = 0.40692395\n",
      "Iteration 95, loss = 0.40380508\n",
      "Iteration 96, loss = 0.40073936\n",
      "Iteration 97, loss = 0.39758017\n",
      "Iteration 98, loss = 0.39447171\n",
      "Iteration 99, loss = 0.39132525\n",
      "Iteration 100, loss = 0.38822746\n",
      "Iteration 101, loss = 0.38508242\n",
      "Iteration 102, loss = 0.38198330\n",
      "Iteration 103, loss = 0.37888878\n",
      "Iteration 104, loss = 0.37579456\n",
      "Iteration 105, loss = 0.37263747\n",
      "Iteration 106, loss = 0.36956742\n",
      "Iteration 107, loss = 0.36647680\n",
      "Iteration 108, loss = 0.36341919\n",
      "Iteration 109, loss = 0.36033695\n",
      "Iteration 110, loss = 0.35726159\n",
      "Iteration 111, loss = 0.35420774\n",
      "Iteration 112, loss = 0.35116067\n",
      "Iteration 113, loss = 0.34816202\n",
      "Iteration 114, loss = 0.34509155\n",
      "Iteration 115, loss = 0.34209942\n",
      "Iteration 116, loss = 0.33908335\n",
      "Iteration 117, loss = 0.33607740\n",
      "Iteration 118, loss = 0.33306722\n",
      "Iteration 119, loss = 0.33010144\n",
      "Iteration 120, loss = 0.32714938\n",
      "Iteration 121, loss = 0.32420470\n",
      "Iteration 122, loss = 0.32128069\n",
      "Iteration 123, loss = 0.31838235\n",
      "Iteration 124, loss = 0.31546288\n",
      "Iteration 125, loss = 0.31257666\n",
      "Iteration 126, loss = 0.30973538\n",
      "Iteration 127, loss = 0.30690914\n",
      "Iteration 128, loss = 0.30405983\n",
      "Iteration 129, loss = 0.30122259\n",
      "Iteration 130, loss = 0.29843551\n",
      "Iteration 131, loss = 0.29566892\n",
      "Iteration 132, loss = 0.29291910\n",
      "Iteration 133, loss = 0.29019441\n",
      "Iteration 134, loss = 0.28747235\n",
      "Iteration 135, loss = 0.28478872\n",
      "Iteration 136, loss = 0.28215249\n",
      "Iteration 137, loss = 0.27953699\n",
      "Iteration 138, loss = 0.27687876\n",
      "Iteration 139, loss = 0.27428685\n",
      "Iteration 140, loss = 0.27174925\n",
      "Iteration 141, loss = 0.26930036\n",
      "Iteration 142, loss = 0.26672061\n",
      "Iteration 143, loss = 0.26426701\n",
      "Iteration 144, loss = 0.26180914\n",
      "Iteration 145, loss = 0.25943396\n",
      "Iteration 146, loss = 0.25705220\n",
      "Iteration 147, loss = 0.25470222\n",
      "Iteration 148, loss = 0.25236566\n",
      "Iteration 149, loss = 0.25010533\n",
      "Iteration 150, loss = 0.24783231\n",
      "Iteration 151, loss = 0.24558187\n",
      "Iteration 152, loss = 0.24338413\n",
      "Iteration 153, loss = 0.24122901\n",
      "Iteration 154, loss = 0.23906371\n",
      "Iteration 155, loss = 0.23693833\n",
      "Iteration 156, loss = 0.23485149\n",
      "Iteration 157, loss = 0.23277806\n",
      "Iteration 158, loss = 0.23073463\n",
      "Iteration 159, loss = 0.22872863\n",
      "Iteration 160, loss = 0.22671249\n",
      "Iteration 161, loss = 0.22473668\n",
      "Iteration 162, loss = 0.22280800\n",
      "Iteration 163, loss = 0.22089387\n",
      "Iteration 164, loss = 0.21898669\n",
      "Iteration 165, loss = 0.21711843\n",
      "Iteration 166, loss = 0.21530469\n",
      "Iteration 167, loss = 0.21349060\n",
      "Iteration 168, loss = 0.21167331\n",
      "Iteration 169, loss = 0.20988736\n",
      "Iteration 170, loss = 0.20814497\n",
      "Iteration 171, loss = 0.20642658\n",
      "Iteration 172, loss = 0.20471847\n",
      "Iteration 173, loss = 0.20302617\n",
      "Iteration 174, loss = 0.20138234\n",
      "Iteration 175, loss = 0.19975587\n",
      "Iteration 176, loss = 0.19815927\n",
      "Iteration 177, loss = 0.19653827\n",
      "Iteration 178, loss = 0.19497095\n",
      "Iteration 179, loss = 0.19345890\n",
      "Iteration 180, loss = 0.19189316\n",
      "Iteration 181, loss = 0.19041390\n",
      "Iteration 182, loss = 0.18890566\n",
      "Iteration 183, loss = 0.18744376\n",
      "Iteration 184, loss = 0.18600220\n",
      "Iteration 185, loss = 0.18456248\n",
      "Iteration 186, loss = 0.18316543\n",
      "Iteration 187, loss = 0.18183637\n",
      "Iteration 188, loss = 0.18047367\n",
      "Iteration 189, loss = 0.17911120\n",
      "Iteration 190, loss = 0.17776442\n",
      "Iteration 191, loss = 0.17644375\n",
      "Iteration 192, loss = 0.17515236\n",
      "Iteration 193, loss = 0.17387655\n",
      "Iteration 194, loss = 0.17262060\n",
      "Iteration 195, loss = 0.17138800\n",
      "Iteration 196, loss = 0.17017439\n",
      "Iteration 197, loss = 0.16897123\n",
      "Iteration 198, loss = 0.16777337\n",
      "Iteration 199, loss = 0.16661673\n",
      "Iteration 200, loss = 0.16545123\n",
      "Iteration 201, loss = 0.16430831\n",
      "Iteration 202, loss = 0.16319710\n",
      "Iteration 203, loss = 0.16210452\n",
      "Iteration 204, loss = 0.16100765\n",
      "Iteration 205, loss = 0.15994372\n",
      "Iteration 206, loss = 0.15887660\n",
      "Iteration 207, loss = 0.15783100\n",
      "Iteration 208, loss = 0.15680285\n",
      "Iteration 209, loss = 0.15579710\n",
      "Iteration 210, loss = 0.15479422\n",
      "Iteration 211, loss = 0.15380340\n",
      "Iteration 212, loss = 0.15283994\n",
      "Iteration 213, loss = 0.15187494\n",
      "Iteration 214, loss = 0.15094381\n",
      "Iteration 215, loss = 0.15000161\n",
      "Iteration 216, loss = 0.14908403\n",
      "Iteration 217, loss = 0.14821482\n",
      "Iteration 218, loss = 0.14728856\n",
      "Iteration 219, loss = 0.14640644\n",
      "Iteration 220, loss = 0.14554715\n",
      "Iteration 221, loss = 0.14469008\n",
      "Iteration 222, loss = 0.14385788\n",
      "Iteration 223, loss = 0.14302167\n",
      "Iteration 224, loss = 0.14220097\n",
      "Iteration 225, loss = 0.14138864\n",
      "Iteration 226, loss = 0.14058586\n",
      "Iteration 227, loss = 0.13979903\n",
      "Iteration 228, loss = 0.13905787\n",
      "Iteration 229, loss = 0.13826406\n",
      "Iteration 230, loss = 0.13752565\n",
      "Iteration 231, loss = 0.13677971\n",
      "Iteration 232, loss = 0.13606094\n",
      "Iteration 233, loss = 0.13533911\n",
      "Iteration 234, loss = 0.13462108\n",
      "Iteration 235, loss = 0.13389263\n",
      "Iteration 236, loss = 0.13319944\n",
      "Iteration 237, loss = 0.13251066\n",
      "Iteration 238, loss = 0.13182798\n",
      "Iteration 239, loss = 0.13117561\n",
      "Iteration 240, loss = 0.13050915\n",
      "Iteration 241, loss = 0.12986200\n",
      "Iteration 242, loss = 0.12922783\n",
      "Iteration 243, loss = 0.12858623\n",
      "Iteration 244, loss = 0.12797810\n",
      "Iteration 245, loss = 0.12739000\n",
      "Iteration 246, loss = 0.12677351\n",
      "Iteration 247, loss = 0.12617494\n",
      "Iteration 248, loss = 0.12557540\n",
      "Iteration 249, loss = 0.12499047\n",
      "Iteration 250, loss = 0.12441254\n",
      "Iteration 251, loss = 0.12385065\n",
      "Iteration 252, loss = 0.12330719\n",
      "Iteration 253, loss = 0.12273035\n",
      "Iteration 254, loss = 0.12222173\n",
      "Iteration 255, loss = 0.12169518\n",
      "Iteration 256, loss = 0.12113719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 257, loss = 0.12061926\n",
      "Iteration 258, loss = 0.12008557\n",
      "Iteration 259, loss = 0.11958641\n",
      "Iteration 260, loss = 0.11909899\n",
      "Iteration 261, loss = 0.11859854\n",
      "Iteration 262, loss = 0.11811809\n",
      "Iteration 263, loss = 0.11764076\n",
      "Iteration 264, loss = 0.11713874\n",
      "Iteration 265, loss = 0.11667168\n",
      "Iteration 266, loss = 0.11622697\n",
      "Iteration 267, loss = 0.11574934\n",
      "Iteration 268, loss = 0.11535044\n",
      "Iteration 269, loss = 0.11488764\n",
      "Iteration 270, loss = 0.11440563\n",
      "Iteration 271, loss = 0.11397476\n",
      "Iteration 272, loss = 0.11353707\n",
      "Iteration 273, loss = 0.11310892\n",
      "Iteration 274, loss = 0.11269045\n",
      "Iteration 275, loss = 0.11229706\n",
      "Iteration 276, loss = 0.11186601\n",
      "Iteration 277, loss = 0.11147876\n",
      "Iteration 278, loss = 0.11108145\n",
      "Iteration 279, loss = 0.11066768\n",
      "Iteration 280, loss = 0.11028526\n",
      "Iteration 281, loss = 0.10988685\n",
      "Iteration 282, loss = 0.10952792\n",
      "Iteration 283, loss = 0.10913519\n",
      "Iteration 284, loss = 0.10877260\n",
      "Iteration 285, loss = 0.10840269\n",
      "Iteration 286, loss = 0.10804028\n",
      "Iteration 287, loss = 0.10769287\n",
      "Iteration 288, loss = 0.10733749\n",
      "Iteration 289, loss = 0.10698348\n",
      "Iteration 290, loss = 0.10666192\n",
      "Iteration 291, loss = 0.10630548\n",
      "Iteration 292, loss = 0.10596717\n",
      "Iteration 293, loss = 0.10564223\n",
      "Iteration 294, loss = 0.10531252\n",
      "Iteration 295, loss = 0.10499418\n",
      "Iteration 296, loss = 0.10466978\n",
      "Iteration 297, loss = 0.10435138\n",
      "Iteration 298, loss = 0.10403627\n",
      "Iteration 299, loss = 0.10374000\n",
      "Iteration 300, loss = 0.10342091\n",
      "Iteration 301, loss = 0.10312782\n",
      "Iteration 302, loss = 0.10282835\n",
      "Iteration 303, loss = 0.10254087\n",
      "Iteration 304, loss = 0.10224666\n",
      "Iteration 305, loss = 0.10195329\n",
      "Iteration 306, loss = 0.10168457\n",
      "Iteration 307, loss = 0.10139709\n",
      "Iteration 308, loss = 0.10110912\n",
      "Iteration 309, loss = 0.10083428\n",
      "Iteration 310, loss = 0.10057064\n",
      "Iteration 311, loss = 0.10029280\n",
      "Iteration 312, loss = 0.10002987\n",
      "Iteration 313, loss = 0.09977420\n",
      "Iteration 314, loss = 0.09953477\n",
      "Iteration 315, loss = 0.09926540\n",
      "Iteration 316, loss = 0.09900388\n",
      "Iteration 317, loss = 0.09874532\n",
      "Iteration 318, loss = 0.09850884\n",
      "Iteration 319, loss = 0.09826799\n",
      "Iteration 320, loss = 0.09801709\n",
      "Iteration 321, loss = 0.09780040\n",
      "Iteration 322, loss = 0.09753916\n",
      "Iteration 323, loss = 0.09730110\n",
      "Iteration 324, loss = 0.09707900\n",
      "Iteration 325, loss = 0.09684580\n",
      "Iteration 326, loss = 0.09661246\n",
      "Iteration 327, loss = 0.09639681\n",
      "Iteration 328, loss = 0.09618161\n",
      "Iteration 329, loss = 0.09595808\n",
      "Iteration 330, loss = 0.09574648\n",
      "Iteration 331, loss = 0.09552722\n",
      "Iteration 332, loss = 0.09532135\n",
      "Iteration 333, loss = 0.09511442\n",
      "Iteration 334, loss = 0.09489638\n",
      "Iteration 335, loss = 0.09470182\n",
      "Iteration 336, loss = 0.09449276\n",
      "Iteration 337, loss = 0.09429043\n",
      "Iteration 338, loss = 0.09408924\n",
      "Iteration 339, loss = 0.09388576\n",
      "Iteration 340, loss = 0.09369780"
     ]
    }
   ],
   "source": [
    "master_neural = sklearn.neural_network.MLPClassifier(activation = \"logistic\", hidden_layer_sizes=(5,), max_iter = 500, solver='sgd', random_state=5, learning_rate = 'adaptive',verbose = 1)\n",
    "master_neural.fit(middle,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_per3(X,eps,delta):\n",
    "    return X - eps*np.sign(delta)\n",
    "def adv_per7(X,eps,delta):\n",
    "    return X + eps*np.sign(delta)\n",
    "delta = X0[y == 3].mean(axis=0) - X0[y == 7].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT_perturbed = np.zeros(XT.shape)\n",
    "theta = 0.5\n",
    "middle = np.zeros((len(Ns),len(XT)))\n",
    "epsilon = np.arange(0,0.5,0.01)\n",
    "Thomas = np.zeros((len(Ns),len(epsilon)))\n",
    "score = []\n",
    "for idx_eps,eps in enumerate(epsilon):\n",
    "    XT_perturbed[yT == 3] = adv_per3(XT[yT == 3],eps,delta)\n",
    "    XT_perturbed[yT == 7] = adv_per7(XT[yT == 7],eps,delta)\n",
    "    for idx_N,N in enumerate(Ns):\n",
    "        X = hill(XT_perturbed,N,theta)\n",
    "        middle[idx_N]=small_neural.predict(X)\n",
    "        Thomas[idx_N][idx_eps]=small_neural.score(X,yT)\n",
    "    \n",
    "    middleT=np.transpose(middle)\n",
    "    score.append(master_neural.score(middleT,yT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(epsilon,score)\n",
    "ax.plot(epsilon,Thomas[len(Thomas)-1])\n",
    "ax.set_title(r\"Even powers; $\\theta$ = %.1f\"%theta)\n",
    "ax.set_xlabel(\"Epsilon\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "plt.legend(['ours','Thomas'], title = \"       N\")\n",
    "#plt.savefig(\"../Figures/Even-powers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = True\n",
    "for i in range(len(score)):\n",
    "    if (score[i]<0.8 and final):\n",
    "        print(epsilon[i])\n",
    "        final = False\n",
    "final = True\n",
    "for i in range(len(Thomas[len(Thomas)-1])):\n",
    "    if (Thomas[len(Thomas)-1][i]<0.8 and final):\n",
    "        print(epsilon[i])\n",
    "        final = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X0_adv_test = np.zeros(X0_test.shape)\n",
    "theta = 0.5\n",
    "epsilon = np.arange(0,0.5,0.01)\n",
    "Ns = np.arange(11)\n",
    "score = np.zeros((len(Ns),len(epsilon)))\n",
    "for idx_eps,eps in enumerate(epsilon):\n",
    "    X0_adv_test[y_test == 3] = adv_per3(X0_test[y_test == 3],eps,delta)\n",
    "    X0_adv_test[y_test == 7] = adv_per7(X0_test[y_test == 7],eps,delta)\n",
    "    for idx_N,N in enumerate(Ns):\n",
    "        X1_adv_test = hill(X0_adv_test,N,theta)\n",
    "        score[idx_N,idx_eps]=mlp_orig.score(X1_adv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for line in score[range(2,12,2),:]:\n",
    "    ax.plot(epsilon,line)\n",
    "    ax.set_title(r\"Even powers; $\\theta$ = %.1f\"%theta)\n",
    "    ax.set_xlabel(\"Epsilon\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    plt.legend([2,4,6,8,10], title = \"       N\")\n",
    "    #plt.savefig(\"../Figures/Even-powers.png\")\n",
    "    \n",
    "fig,ax = plt.subplots()\n",
    "for line in score[range(1,11,2),:]:\n",
    "    ax.plot(epsilon,line)\n",
    "    ax.set_title(r\"Odd powers; $\\theta$ = %.1f\"%theta)\n",
    "    ax.set_xlabel(\"Epsilon\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    plt.legend(range(1,11,2), title = \"        N\")\n",
    "    #plt.savefig(\"../Figures/Odd-powers.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_naive = np.zeros((len(epsilon),1))\n",
    "for idx_eps,eps in enumerate(epsilon):\n",
    "    X0_adv_test[y_test == 3] = adv_per3(X0_test[y_test == 3],eps,delta)\n",
    "    X0_adv_test[y_test == 7] = adv_per7(X0_test[y_test == 7],eps,delta)\n",
    "    score_naive[idx_eps]=mlp_orig.score(X0_adv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in score_naive.T:\n",
    "    plt.plot(epsilon,line)\n",
    "    plt.title(\"Naive adversarial perturbation\")\n",
    "    plt.legend([\"No transformation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute gradient manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = np.max((0,x[i]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill(x,n,theta):\n",
    "#     return x**n\n",
    "    return x**n/(x**n + theta**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x,use_hill,N,theta,mlp):\n",
    "    W = mlp.coefs_\n",
    "    b = mlp.intercepts_\n",
    "    if use_hill:\n",
    "        y = hill(x,N,theta)\n",
    "    else:\n",
    "        y = x[:]\n",
    "    return sigmoid(np.dot(relu(np.dot(y,W[0])+b[0]),W[1])+b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_score(x,use_hill,N,theta,mlp):\n",
    "    grad = np.zeros(x.shape)\n",
    "    for i in range(len(x)):\n",
    "        yp = x.copy(); yp[i] += 10/255; \n",
    "        ym = x.copy(); ym[i] -= 10/255;\n",
    "        grad[i] = 255/2*(score(yp,use_hill,N,theta,mlp)-score(ym,use_hill,N,theta,mlp))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_grad(x0,use_hill,N,theta,mlp,eps):\n",
    "    num_iter = 0; \n",
    "    x = x0.copy()\n",
    "    pred = mlp.predict(x0.reshape(1,-1))\n",
    "    new_pred = mlp.predict(x.reshape(1,-1))\n",
    "    pm = (pred-5)/2 #3 -> -1; 7 -> +1\n",
    "    while new_pred == pred:\n",
    "        grad = grad_score(x,use_hill,N,theta,mlp)\n",
    "        x -= pm*eps*grad[:]\n",
    "        new_pred = mlp.predict(x.reshape(1,-1))\n",
    "        print(score(x,use_hill,N,theta,mlp))\n",
    "        num_iter += 1\n",
    "    return x,num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X0_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-ce4e7362fd59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0muse_hill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX0_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmlp_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X0_test' is not defined"
     ]
    }
   ],
   "source": [
    "use_hill=True;N=10;theta=0.5\n",
    "x0 = X0_test[y_test==3][1000]\n",
    "grad = grad_score(x0,True,N,theta,mlp_orig)\n",
    "plt.imshow(grad.reshape(28,28),cmap=plt.cm.gray)\n",
    "plt.axis('off');plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99974438]\n",
      "[0.99967377]\n",
      "[0.99958719]\n",
      "[0.99950201]\n",
      "[0.99943272]\n",
      "[0.9993761]\n",
      "[0.99932715]\n",
      "[0.99928423]\n",
      "[0.99924613]\n",
      "[0.99921094]\n",
      "[0.99917637]\n",
      "[0.99913971]\n",
      "[0.9990965]\n",
      "[0.99903809]\n",
      "[0.99895625]\n",
      "[0.99886442]\n",
      "[0.99875223]\n",
      "[0.99852028]\n",
      "[0.99830909]\n",
      "[0.99825342]\n",
      "[0.9982097]\n",
      "[0.99815806]\n",
      "[0.9980618]\n",
      "[0.99777888]\n",
      "[0.99733757]\n",
      "[0.99723265]\n",
      "[0.997112]\n",
      "[0.99689509]\n",
      "[0.99675982]\n",
      "[0.99656834]\n",
      "[0.9958072]\n",
      "[0.99295332]\n",
      "[0.99285109]\n",
      "[0.99279339]\n",
      "[0.99274333]\n",
      "[0.99268482]\n",
      "[0.99257579]\n",
      "[0.99196339]\n",
      "[0.98923573]\n",
      "[0.98825682]\n",
      "[0.98464329]\n",
      "[0.98453565]\n",
      "[0.98435471]\n",
      "[0.98365773]\n",
      "[0.96918899]\n",
      "[0.97395546]\n",
      "[0.94493904]\n",
      "[0.84103246]\n",
      "[0.87014672]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e42dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = X0_test[y_test==7][1000]\n",
    "x1,num_iter = iter_grad(x0,True,10,theta,mlp_orig,5)\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(x0.reshape(28,28),cmap=plt.cm.gray)\n",
    "ax[1].imshow(x1.reshape(28,28),cmap=plt.cm.gray)\n",
    "# ax[2].imshow(hill(x.reshape(28,28),N,theta),cmap=plt.cm.gray)\n",
    "\n",
    "[a.axis('off') for a in ax]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X0_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-0833f8787178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX0_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX0_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrad_xF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmlp_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-237-0833f8787178>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX0_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX0_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrad_xF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmlp_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X0_test' is not defined"
     ]
    }
   ],
   "source": [
    "sample = [int(len(X0_test)*random.random()) for _ in range(10)]\n",
    "\n",
    "for i in sample:\n",
    "    x = X0_test[i]\n",
    "    grad_xF = grad_score(x,False,0,0,mlp_orig)\n",
    "    print(sum(grad_xF**2))\n",
    "    grad_xT = grad_score(x,True,10,0.5,mlp_orig)\n",
    "    fig,ax = plt.subplots(1,3)\n",
    "    ax[0].imshow(x.reshape(28,28),cmap=plt.cm.gray)\n",
    "    ax[1].imshow((grad_xF).reshape(28,28),cmap=plt.cm.gray)\n",
    "    ax[2].imshow((grad_xT).reshape(28,28),cmap=plt.cm.gray)\n",
    "    [a.axis('off') for a in ax]\n",
    "    plt.show()\n",
    "# print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01646657]\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(score(x,False,0,0,mlp_orig))\n",
    "print(y_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 1360\n",
    "eps = 0.5\n",
    "use_hill = True\n",
    "N = 2\n",
    "theta = 0.8\n",
    "x = X0_test[y_test == 3][num].copy()\n",
    "pred = y_test[y_test == 3][num]\n",
    "# pred = score(x,use_hill,N,theta,mlp_orig)\n",
    "print(pred)\n",
    "num_iter = 0\n",
    "# while pred == y_test[num]:\n",
    "while pred < 0.98:\n",
    "    print(score(x,use_hill,N,theta,mlp_orig))\n",
    "    grad = grad_score(x,use_hill,N,theta,mlp_orig)\n",
    "    if y_test[num] == 3:\n",
    "        x += eps*grad[:]\n",
    "    elif y_test[num] == 7:\n",
    "        x -= eps*grad[:]\n",
    "#     pred = mlp_orig.predict(x.reshape(1,-1))\n",
    "    pred = score(x,use_hill,N,theta,mlp_orig)\n",
    "    num_iter += 1\n",
    "print(num_iter)\n",
    "fig,ax = plt.subplots(1,3)\n",
    "ax[0].imshow(X0_test[y_test == 3][num].reshape(28,28),cmap=plt.cm.gray)\n",
    "ax[1].imshow(grad.reshape(28,28),cmap=plt.cm.gray)\n",
    "ax[2].imshow(hill(x.reshape(28,28),N,theta),cmap=plt.cm.gray)\n",
    "[a.axis('off') for a in ax]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e0df160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e3f95c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABR1JREFUeJzt3b9N80AAxuEYEn2io4CSNZiBIqnomYFRGIINQsEYVCxAGZAoaFD++CsofZESiB3nzfOUp4BPYP10ks+Xqq7rAQCH72TfEwBgNwQdIISgA4QQdIAQgg4QQtABQgg6QAhBBwgh6AAhBB0gxLDLi1VV5ZwBWlXXdbWP67q3adsm97YVOkAIQQcIIegAIQQdIISgA4QQdIAQgg4QQtABQgg6QAhBBwgh6AAhBB0ghKADhBB0gBCCDhBC0AFCCDpACEEHCCHoACEEHSCEoAOEEHSAEIIOEELQAUIIOkAIQQcIIegAIQQdIISgA4QQdIAQgg4QYrjvCfBjPB43xqbT6cY/f3l5WRx/f3//9ZyAw2KFDhBC0AFCCDpACEEHCFHVdd3dxaqqu4v12F8fgG6j9LA0+UFpXdfVPq7r3qZtm9zbVugAIQQdIISgA4QQdIAQgg4Qwqv/LSrtZhkMyjtaRqNRY2yxWPz5WrPZrDE2mUyKn316etr4ekD/WKEDhBB0gBCCDhBC0AFCePV/R7b5O1ZVd2+nD4fN597z+bz42S7n1Rav/h+309PT4vhyuex4Jrvn1X+AIyLoACEEHSCEoAOEEHSAEF7931Jp18g6fdg1cn5+vu8pQGdWq9W+p7BXVugAIQQdIISgA4QQdIAQXv3fUl9f8V/n0Ob7V179/711r82X7qFjf/i4D179Bzgigg4QQtABQgg6QAhBBwjh1f8DtM2XVpSMRqNdTocQ646JuLq6aoy9vLy0PR1+wQodIISgA4QQdIAQgg4QwkPRFo3H4+L48/NzY+zm5qYxNp1Odz6nwWAwWCwWrfxeDtvt7W1x/PHxsTF2f39f/OzDw0NjrHSkwHK5LP586fiJdUdSOH6gyQodIISgA4QQdIAQgg4QwnnoO9Ll33EbCWecb8N56Lt3dnbWGCu9PToYDAaz2awx9vX11Rhb92C+dL96+PnDeegAR0TQAUIIOkAIQQcIIegAIexy6bGLi4vieGknwTp2uXTDvb2ddfflyUlzjbnumIBjY5cLwBERdIAQgg4QQtABQjgPvcc+Pz83/qwvfiZB6UiAY3uw/xdW6AAhBB0ghKADhBB0gBCCDhDCLpcem8/nG3923RcGQB9dX18Xx+/u7jqeSRYrdIAQgg4QQtABQgg6QAgPRYHOvb6+Fsc/Pj46nkkWK3SAEIIOEELQAUIIOkAIQQcIYZdLTwyHm/8rJpNJizOB9q2739/e3jqeSRYrdIAQgg4QQtABQgg6QIiqruvuLlZV3V3swJQeEq07D300GjXGnIf+o67rvXxFvHt7O//+/SuOf39/dzyTw7HJvW2FDhBC0AFCCDpACEEHCCHoACHscumJbf4PVbWXjRwHwS6X/jk5aa4bV6vVHmZy2OxyATgigg4QQtABQgg6QAjnoQOt8gC0O1boACEEHSCEoAOEEHSAEIIOEMIuF6BVpaMqujxy5JhYoQOEEHSAEIIOEELQAUJ4KAq0ygPQ7lihA4QQdIAQgg4QQtABQgg6QAi7XHpsNBrtewrAAbFCBwgh6AAhBB0ghKADhPBQtCdKZ0YDbMMKHSCEoAOEEHSAEIIOEELQAUIIOkAIQQcIIegAIQQdIISgA4SofCM3QAYrdIAQgg4QQtABQgg6QAhBBwgh6AAhBB0ghKADhBB0gBCCDhBC0AFCCDpACEEHCCHoACEEHSCEoAOEEHSAEIIOEELQAUIIOkAIQQcIIegAIQQdIMR/5IjrnFD6W6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e493f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABHhJREFUeJzt3UtO40oAQFGMEDBDYs4aYAewBVbKBlhEWAVMEQxAQvIbvGEcKel8HC7nDEvpdkFXX5XksjOM43gCwO93OvcEANgNQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiDg75MWGYfCeAfZqHMdhjuta2+zbOmvbDh0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0g4mzuCfC/29vbpbHFYrH2n7+8vJwc//7+/uc5Ab+LHTpAhKADRAg6QISgA0QM4zge7mLDcLiLHbFtb4BuYupmaflG6TiOwxzXtbbZt3XWth06QISgA0QIOkCEoANECDpAhEf/92jqNMvJyfSJlmHY7nDGqmt9fX0tjd3d3U1+9uXlZas5APOyQweIEHSACEEHiBB0gAiP/u/IJr/HbW+AbmvVXOee1y549J8qj/4D/CGCDhAh6AARgg4QIegAER7936NjODVycXEx9xSAA7FDB4gQdIAIQQeIEHSACDdFN3TIVyXswtT70IEmO3SACEEHiBB0gAhBB4gQdIAIp1wiftMXbHCczs/PJ8evr6+Xxt7e3vY9Hf6BHTpAhKADRAg6QISgA0S4KbpHt7e3k+MvLy9rfXaxWOx8TrDKw8PD5Pjz8/PS2OPj4+Rnn56edjklNmSHDhAh6AARgg4QIegAEcMh3+89DMPvepn4Bo71Pel/7anQcRxn+YHLa/v0dHnfd3V1NfnZz8/PpbGfn5+lsWP9/3LM1lnbdugAEYIOECHoABGCDhAh6AARTrkcsYuLi8nxr6+vtf8Op1wOw9pm35xyAfhDBB0gQtABIgQdIML70I/Y9/f32p/9azc/aZo6pGFtr88OHSBC0AEiBB0gQtABIgQdIMIplyPmSwCourm5mRy/v78/8Exa7NABIgQdIELQASIEHSDCTVHg4F5fXyfHPz4+DjyTFjt0gAhBB4gQdIAIQQeIEHSACKdcfqG7u7u5pwBbOT2d3ku+v78feCYtdugAEYIOECHoABGCDhAxHPKd28MweMH3Blb92/gW9NXGcZzll2Ntb2bVGvYdAKuts7bt0AEiBB0gQtABIgQdIELQASI8+n8k3N3nL7He98MOHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0g4mzuCbDaMAxzTwH4RezQASIEHSBC0AEiBB0gwk3RI+EGKLAtO3SACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gYxnGcew4A7IAdOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QMR/ASSn0z8pyWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ef78be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABFVJREFUeJzt3T1OG0EAgFEWEIqouIDd03AA7i9qzmBfgQYke1OkZC3Z8f/n98qRkx1g82WknR2GcRzvALh+9+eeAACHIegAEYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGPp7zYMAzOGeCoxnEcznFd9zbHts29bYUOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGCDhAh6AARgg4QIegAEYIOEPF47gnwz2w2+zW2WCy2/vMPDw+T4+v1+r/nBFwXK3SACEEHiBB0gAhBB4jwUPQM9n0AOmW1Wk2OTz0s9aAUmqzQASIEHSBC0AEiBB0gQtABIuxyOaKp3Sx3d9M7WoZhOMq1pna/zOfzyc8ul8u95gCclxU6QISgA0QIOkCEoANEDOM4nu5iw3C6i53YLt/HfR+A7mvTXM89r0MYx/EsX0T53uYybHNvW6EDRAg6QISgA0QIOkCEoANEePX/iC5h18j9vf+z4Vb41w4QIegAEYIOECHoABEeiu7olEclHMLUeehAkxU6QISgA0QIOkCEoANECDpAhF0uEdf0Cza4TJuOiXh+fv419vX1dezp8B+s0AEiBB0gQtABIgQdIMJD0SOazWaT48vlcqvPLhaLg88JNnl7e5sc//z8/DX2/v4++dmPj4+DzondWKEDRAg6QISgA0QIOkDEcMrzvYdhuK7DxHdwqeek39pboeM4nuULLt/bU/78+TM5/vPz82tsvV4fezo3YZt72wodIELQASIEHSBC0AEiBB0gwi6XC7bpfOrVarX132GXy2m4tzk2u1wAboigA0QIOkCEoANEOA/9gu3yyvStPfykaWqThnt7e1boABGCDhAh6AARgg4QIegAEXa5XLBL/aUZsK+Xl5fJ8dfX1xPPpMUKHSBC0AEiBB0gQtABIpyHfsF2+dl4Pfof56Ffh03369PT06+x7+/vY0/nKjgPHeCGCDpAhKADRAg6QISgA0R49f8Kzefzc08B9rJpl4sdLfuxQgeIEHSACEEHiBB0gAiv/l+wTT8br/lv5tV/qrz6D3BDBB0gQtABIgQdIELQASK8+n8hTrnbCGiyQgeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiHg89wTYbBiGc08BuCJW6AARgg4QIegAEYIOEOGh6IXwABTYlxU6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANEDOM4nnsOAByAFTpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkDEX+V4oaMV7b9IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13de2ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABClJREFUeJzt3btO40AAQFFmgxBtUlNR8v/fQsknJD0S8haUONqweTi5Oae0gjyAdTXSzDhjmqYHAG7fn6UHAMBpCDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QMTjJW82xvCeAc5qmqaxxH0925zbIc+2GTpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAxOPSA+Dber3+cW273R7882OMUw4HuEFm6AARgg4QIegAEYIOEGFRdAHHLoDOmaZp9rrFUrgfZugAEYIOECHoABGCDhAh6AARdrmc0dxuloeH+R0tx+5G2Xevud0vm81m9rO73e6oMQDLMkMHiBB0gAhBB4gQdICIse/I+FluNsblbnZhv/k7Ln0cv/yagGmaFvklys821+GQZ9sMHSBC0AEiBB0gQtABIgQdIMLR/zMq7BoBbocZOkCEoANECDpAhKADRFgU/aVLvirhFG5tvMD/M0MHiBB0gAhBB4gQdIAIQQeIsMsl4pa+YIPb8vT09OPa5+fnAiPhX8zQASIEHSBC0AEiBB0gwqLoGa3X69nru93uoM9ut9uTjwn2eX19nb3+8fHx49rb29vsZ9/f3086Jn7HDB0gQtABIgQdIELQASLGJd+XPcbIvpz7Wt87fm+nQqdpWuQXLj/bc1ar1ez1r6+vC4/kfhzybJuhA0QIOkCEoANECDpAhKADRDj6fyKX3E1yrTtquB92s1wnM3SACEEHiBB0gAhBB4iwKBpxb0f8aZpb8PdsH84MHSBC0AEiBB0gQtABIgQdIMIulyvmiD9Vz8/Ps9dfXl4uPJIWM3SACEEHiBB0gAhBB4gYl1x4u7dvRj/Wb/43jkd/O+Sb0c/Bs30aq9XqxzXvXv92yLNthg4QIegAEYIOECHoABGCDhDh6P8N2mw2Sw8BzsKOluOYoQNECDpAhKADRAg6QISj/1ds3//GMf/9HP2nytF/gDsi6AARgg4QIegAEYIOEOHo/5W45G4joMkMHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0g4nHpAbDfGGPpIQA3xAwdIELQASIEHSBC0AEiLIpeCQugwLHM0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIGJM07T0GAA4ATN0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSAiL/DSo06R5gshQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e97cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 [4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABBpJREFUeJzt3b1OKzkAgFG8pEs6Cjre/7no6JMSeQtKJtqw+ZnkyznlKFdjwPeTpbEnY875AsDj+2ftAQBwGYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABGCDhCxueXNxhjeM8BVzTnHGvc1t7m2U+a2FTpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAxGbtAfBju93+urbf70/+92OMSw4HeEBW6AARgg4QIegAEYIOEOGh6ArOfQC6ZM65eN3DUngeVugAEYIOECHoABGCDhAh6AARdrlc0dJulpeX5R0t5+5GOXavpd0vu91u8bOHw+GsMQDrskIHiBB0gAhBB4gQdICIcezI+FVuNsbtbnZjf/k9rn0cv/yagDnnKj9EeW5zH06Z21boABGCDhAh6AARgg4QIegAEY7+X1Fh1wjwOKzQASIEHSBC0AEiBB0gwkPRP7rlqxIu4dHGC/x/VugAEYIOECHoABGCDhAh6AARdrlEPNIXbPBYXl9ff137/v5eYST8Fyt0gAhBB4gQdIAIQQeI8FD0irbb7eL1w+Fw0mf3+/3FxwTHvL+/L17/+vr6de3j42Pxs5+fnxcdE39jhQ4QIegAEYIOECHoABHjlu/LHmNkX859r+8df7ZToXPOVX7g8txecmxe3ev/g4JT5rYVOkCEoANECDpAhKADRAg6QISj/xdyy90kdhKwNnPwPlmhA0QIOkCEoANECDpAhIeiEc92xJ+mpYet5vbprNABIgQdIELQASIEHSBC0AEi7HK5Y45XU7XZLKfn7e3txiNpsUIHiBB0gAhBB4gQdICIccsHb8/2zejn+svfxvHoH6d8M/o1mNuXsTSPbQ74ccrctkIHiBB0gAhBB4gQdIAIQQeIcPT/Ae12u7WHAFdhR8t5rNABIgQdIELQASIEHSDC0f87duxv45j/cY7+U+XoP8ATEXSACEEHiBB0gAhBB4hw9P9OOPIMnMsKHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gYrP2ADhujLH2EIAHYoUOECHoABGCDhAh6AARHoreCQ9AgXNZoQNECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QMSYc649BgAuwAodIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0gQtABIgQdIELQASIEHSBC0AEiBB0g4l+eY4z7DTodRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14b1ba780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.arange(2,30,4):\n",
    "    y = hill(x.reshape(1,-1),i,theta)\n",
    "    print(i, mlp_orig.predict(y))\n",
    "    fig,ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(hill(X0_test[num].reshape(28,28),i,theta),cmap=plt.cm.gray)\n",
    "    ax[1].imshow(y.reshape(28,28),cmap=plt.cm.gray)\n",
    "    [a.axis('off') for a in ax]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[760, 406, 638, 1045, 322]\n",
      "[0.99771786]\n",
      "[0.99979101]\n",
      "[0.97157543]\n",
      "[0.9999972]\n",
      "[0.99999471]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ4odQ/wJpMNgUMWlCGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+CGU+CGU+CHUP7uJJmXjI1EKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABNlJREFUeJzt3MtxFEkUQFHVBF7o4wYt2QHYwc8M\nAtmBkB8t3ECSHTX7iVBW018095xtdqpywY1cPKqmeZ7PgJ5/Tn0A4DTED1HihyjxQ5T4IUr8ECV+\niBI/RIkfot4c82HTNPnvhHBg8zxPm/zOzQ9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU\n+CFK/BD15tQHeC1+//794trl5eVw73q9Hq4/PT3ttH/k+fl5uP7u3but//bZ2dnZxcXF1us/f/4c\n7v3y5ctWZ2Izbn6IEj9EiR+ixA9R4oco8UOU+CFqmuf5eA+bpuM9bM8+ffr04tr379+PeJKOz58/\nD9dvb2+PdJLXZZ7naZPfufkhSvwQJX6IEj9EiR+ixA9R4ococ/4Njd7Z//Hjx3Dv9fX1vo+zscfH\nx+H6w8PDQf/+yNIcf+l9/w8fPmz97P8zc35gSPwQJX6IEj9EiR+ixA9R4oco3+3f0GiefXNzM9y7\nNI8+Pz8frr/m99ZXq9WLa0tzfg7LzQ9R4oco8UOU+CFK/BAlfogSP0SZ8x/B3d3dqY9wMldXV6c+\nAi9w80OU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkforzSy0G9ffv21EfgBW5+\niBI/RIkfosQPUeKHKPFDlPghypyfg7q+vt567/39/R5Pwn+5+SFK/BAlfogSP0SJH6LED1Hihyhz\n/ldgtVoN19fr9Ytrj4+Pw70PDw/D9aX9v379Gq7vMufnsNz8ECV+iBI/RIkfosQPUeKHKPFDlDn/\nK/D8/DxcH83iLy8vh3uX1k/p27dvw/Xz8/Ph+u3t7T6P87/j5oco8UOU+CFK/BAlfogSP0QZ9b0C\nS6/Vfv369cW1jx8/DvdeXFwM15de+V163XiXUeLSs0evMrPMzQ9R4oco8UOU+CFK/BAlfogSP0RN\n8zwf72HTdLyHcRS7fFZ8aU5/c3Oz1Znq5nmeNvmdmx+ixA9R4oco8UOU+CFK/BAlfogy5+egRv++\nlr5TcHV1te/jJJjzA0PihyjxQ5T4IUr8ECV+iBI/RPluPzs55Hf5OSw3P0SJH6LED1HihyjxQ5T4\nIcqoj50svZbL38vND1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EeZ+f\nnaxWq1MfgS25+SFK/BAlfogSP0SJH6LED1Hihyhzfnby/v37Ux+BLbn5IUr8ECV+iBI/RIkfosQP\nUeKHKHN+dvL09LT13vv7+z2ehD/l5oco8UOU+CFK/BAlfogSP0QZ9bGT9Xq99frd3d2+j8MfcPND\nlPghSvwQJX6IEj9EiR+ixA9R0zzPx3vYNB3vYRA1z/O0ye/c/BAlfogSP0SJH6LED1HihyjxQ9RR\n5/zA38PND1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco\n8UOU+CFK/BAlfogSP0T9C1Top1V0gaW8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0KJH0KJH0KJH0KJH0L9DXahC2rauJq2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUOKHUOKHUOKHUOKHUOKHUP8BtE3XQ0iQk5gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = [int(len(X0_test[y_test == 7])*random.random()) for _ in range(5)]\n",
    "print(sample)\n",
    "score7 = [print(score(X0_test[y_test == 7][i],False,0,0,mlp_orig)) for i in sample]\n",
    "for i in sample:\n",
    "    x = X0_test[y_test == 7][i]\n",
    "    plt.imshow(x.reshape(28,28),cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]])\n",
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "N = 2; theta = 0.8\n",
    "sample = [1359, 189, 1314, 366, 1129, 1045]\n",
    "epsilon = np.arange(0.2,1.2,0.2)\n",
    "num_iter_table = [np.zeros((len(sample),len(epsilon)))]*2\n",
    "\n",
    "for i,x in enumerate(X0_test[y_test==7][sample]):\n",
    "    for j,eps in enumerate(epsilon):\n",
    "        num_iter_table[0][i,j] = iter_grad(x,7,False,N,theta,mlp_orig,eps)\n",
    "        num_iter_table[1][i,j] = iter_grad(x,7,True,N,theta,mlp_orig,eps)\n",
    "pprint(num_iter_table[0])\n",
    "pprint(num_iter_table[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
